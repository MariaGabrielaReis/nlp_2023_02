{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba097e1d",
   "metadata": {
    "papermill": {
     "duration": 0.005403,
     "end_time": "2023-08-29T01:49:57.131173",
     "exception": false,
     "start_time": "2023-08-29T01:49:57.125770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exercícios: Introdução à PLN\n",
    "Fonte: CARVALHO, Fabrício Galende Marques de. **Notas de aula da disciplina processamento de linguagem natural.** São José dos Campos, 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e92910b",
   "metadata": {
    "papermill": {
     "duration": 0.004204,
     "end_time": "2023-08-29T01:49:57.140175",
     "exception": false,
     "start_time": "2023-08-29T01:49:57.135971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Terminologia e conceitos\n",
    "---\n",
    "\n",
    "1. Selecione uma obra literária de domínio público e ilustre a variedade de dados presente. Considere, por exemplo, a construção de frases, orações, etc. e compare com expressões de uso corrente.\n",
    "\n",
    "**Resposta:** Selecionada a obra \"A Ela\", de Machado de Assis, podemos observar particularidades do autor e do período que o conto foi escrito (há mais de 80 anos atrás), como o uso de palavras mais rebuscadas, pronomes de tratamento (como no trecho “Vê V. Exa., Sr. presidente, que nesse tempo, o nobre deputado era inimigo de todas as leis\n",
    "opressoras.”) e forma de escrever mais extensa, que hoje encaramos como \"poético\", como na frase \"As cartas ao Dr. Lemos começaram a escassear, até que de todo cessaram de aparecer.\", que, em vocabulário atual, poderia ser substituído por \"Dr. Lemos recebia cada vez menos cartas, até que pararam de vir.\".\n",
    "\n",
    "2. Exemplifique uma sentença, escrita na língua portuguesa, que pode surgir em um site de pré-atendimento em uma concessionária, que potencialmente seja difícil de ser interpretado por um chatbot. Explique sua resposta em termos de estruturação da sentença e suponha que ela esteja gramaticalmente correta.\n",
    "\n",
    "**Resposta:** A sentença \"queria uma moto boa para dar grau\" pode ser difícil de ser interpretada por um chatbot pois, apesar de metade da frase ser bastante clara (é possível perceber o desejo de comprar uma moto, dado o contexto), não é possível caracterizar o que seria uma \"moto boa para dar grau\", necessitando de mais informações antes de oferecer algum produto específico.\n",
    "\n",
    "3. Sistemas de PLN são geralmente compostos por modelos que são treinados utilizando corpora de texto. Por que modelos que são válidos hoje podem não mais ser adequados daqui a dois anos?\n",
    "\n",
    "**Resposta:** Dado que corpora é o conjunto de corpus, que por sua vez é um conjunto de dados lingúisticos reais pertencentes a uma língua, e que a língua é um elemento dinâmico (expressões novas são acrescentadas, palavras caem em desuso, etc), um sistema de PLN treinado hoje pode não ser mais tão adequado daqui a 2 anos, já que palavras que não estão em seu vocabulário podem surgir ou palavras antigas podem trocar de significado.\n",
    "\n",
    "4. Por que a utilização de emojis ou outros símbolos não presentes na linguagem textual formal podem dificultar a operação de um sistema de PLN?\n",
    "\n",
    "**Resposta:** A utilização de emojis ou outros símbolos não presentes na linguagem textual formal podem dificultar a operação de um sistema de PLN pois dependem de contexto para entendimento de seu significado, e ainda podem levar à interpretações errôneas.\n",
    "\n",
    "5. Dê um exemplo de sentença em um processo comunicativo onde os referentes considerados pelo transmissor e pelo receptor podem ser distintos caso não haja adequada contextualização do processo comunicativo.\n",
    "\n",
    "**Resposta:** A frase \"preciso comprar uma bateria nova\" pode ser entendida tanto como a necessidade de comprar uma \"pilha\" nova, quanto comprar um \"instrumento\" novo.\n",
    "\n",
    "6. Exemplifique uma saída para o processo de lematização e stemização. Considere a seguinte sentença:\n",
    "> “Assim que amanheceu, os estudantes, apressados, acordaram e saíram correndo para fazer a prova”.\n",
    "\n",
    "**Resposta:** A lematização é um processo que considera os lemas das palavras (sua forma base), já a stemização não considera tais lemas, apenas remove os afixos da palavra e retorna um elemento que tem ou não significado, assim, uma possível saída para a entrada sugerida seria:\n",
    "\n",
    "| Palavra    | Lema    | Stem  |\n",
    "|:-----------|:--------|:------|\n",
    "| Assim      | Assim   | ssim  |\n",
    "| que        | que     | que   |\n",
    "| amanheceu  | manhã   | manh  |\n",
    "| os         | o       | o     |\n",
    "| estudantes | estudo  | estud |\n",
    "| apressados | pressa  | press |\n",
    "| acordaram  | acordar | cord  |\n",
    "| e          | e       | e     |\n",
    "| saíram     | sair    | sa    |\n",
    "| correndo   | correr  | corr  |\n",
    "| para       | para    | para  |\n",
    "| fazer      | fazer   | faz   |\n",
    "| a          | a       | a     |\n",
    "| prova      | prova   | prova |\n",
    "\n",
    "7. Cite dois possíveis usos das tags do tipo POS. Forneça exemplos com sentenças simples, expressas na língua portuguesa ou inglesa.\n",
    "\n",
    "**Resposta:** Como comentado em aula, a rotularização utilizando as tags POS podem ser muito úteis para o caso de substituição/entendimento do significado de emojis (como na frase \"eu ❤ você\") ou análise de sentimentos (como perceber que a frase \"estou feliz da vida!\" significa que a pessoa está muito feliz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8895900b",
   "metadata": {
    "papermill": {
     "duration": 0.004044,
     "end_time": "2023-08-29T01:49:57.148537",
     "exception": false,
     "start_time": "2023-08-29T01:49:57.144493",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prática de programação\n",
    "---\n",
    "\n",
    "1. Baseando-se no código-fonte fornecido pelo professor, exemplifique o carregamento da biblioteca NLTK, em Python, e efetue a tokenização de um texto em português pertencente a alguma obra literária de domínio público. Utilize um texto de pelo menos 2000 caracteres. Mostre o funcionamento do seu programa e descreva ao menos 5 POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a2b668d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T01:49:57.159486Z",
     "iopub.status.busy": "2023-08-29T01:49:57.158848Z",
     "iopub.status.idle": "2023-08-29T01:50:45.610961Z",
     "shell.execute_reply": "2023-08-29T01:50:45.609274Z"
    },
    "papermill": {
     "duration": 48.461417,
     "end_time": "2023-08-29T01:50:45.614145",
     "exception": false,
     "start_time": "2023-08-29T01:49:57.152728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "/opt/conda/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\r\n",
      "  warn(RuntimeWarning(msg))\r\n",
      "[nltk_data] Downloading collection 'popular'\r\n",
      "[nltk_data]    | \r\n",
      "[nltk_data]    | Downloading package cmudict to\r\n",
      "[nltk_data]    |     /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\r\n",
      "[nltk_data]    | Downloading package gazetteers to\r\n",
      "[nltk_data]    |     /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\r\n",
      "[nltk_data]    | Downloading package genesis to\r\n",
      "[nltk_data]    |     /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\r\n",
      "[nltk_data]    | Downloading package gutenberg to\r\n",
      "[nltk_data]    |     /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\r\n",
      "[nltk_data]    | Downloading package inaugural to\r\n",
      "[nltk_data]    |     /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\r\n",
      "[nltk_data]    | Downloading package movie_reviews to\r\n",
      "[nltk_data]    |     /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\r\n",
      "[nltk_data]    | Downloading package names to /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package names is already up-to-date!\r\n",
      "[nltk_data]    | Downloading package shakespeare to\r\n",
      "[nltk_data]    |     /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\r\n",
      "[nltk_data]    | Downloading package stopwords to\r\n",
      "[nltk_data]    |     /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\r\n",
      "[nltk_data]    | Downloading package treebank to\r\n",
      "[nltk_data]    |     /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\r\n",
      "[nltk_data]    | Downloading package twitter_samples to\r\n",
      "[nltk_data]    |     /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\r\n",
      "[nltk_data]    | Downloading package omw to /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package omw is already up-to-date!\r\n",
      "[nltk_data]    | Downloading package omw-1.4 to\r\n",
      "[nltk_data]    |     /usr/share/nltk_data...\r\n",
      "[nltk_data]    | Downloading package wordnet to\r\n",
      "[nltk_data]    |     /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\r\n",
      "[nltk_data]    | Downloading package wordnet2021 to\r\n",
      "[nltk_data]    |     /usr/share/nltk_data...\r\n",
      "[nltk_data]    | Downloading package wordnet31 to\r\n",
      "[nltk_data]    |     /usr/share/nltk_data...\r\n",
      "[nltk_data]    | Downloading package wordnet_ic to\r\n",
      "[nltk_data]    |     /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\r\n",
      "[nltk_data]    | Downloading package words to /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package words is already up-to-date!\r\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\r\n",
      "[nltk_data]    |     /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\r\n",
      "[nltk_data]    | Downloading package punkt to /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\r\n",
      "[nltk_data]    | Downloading package snowball_data to\r\n",
      "[nltk_data]    |     /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\r\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\r\n",
      "[nltk_data]    |     /usr/share/nltk_data...\r\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\r\n",
      "[nltk_data]    |       to-date!\r\n",
      "[nltk_data]    | \r\n",
      "[nltk_data]  Done downloading collection popular\r\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\r\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\r\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\r\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\r\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\r\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\r\n",
      "Collecting pt-core-news-sm==3.6.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.6.0/pt_core_news_sm-3.6.0-py3-none-any.whl (13.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: en_core_web_sm in /opt/conda/lib/python3.10/site-packages (3.6.0)\r\n",
      "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in /opt/conda/lib/python3.10/site-packages (from en_core_web_sm) (3.6.0)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (1.0.4)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (1.0.9)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (2.0.7)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (3.0.8)\r\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (8.1.10)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (1.1.2)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (2.4.6)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (2.0.8)\r\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (0.9.0)\r\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (0.10.2)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (6.3.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (4.65.0)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (1.23.5)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (2.31.0)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (1.10.9)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (3.1.2)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (59.8.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (21.3)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en_core_web_sm) (3.3.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.7.0,>=3.6.0->en_core_web_sm) (3.0.9)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en_core_web_sm) (4.6.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en_core_web_sm) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en_core_web_sm) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en_core_web_sm) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en_core_web_sm) (2023.5.7)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en_core_web_sm) (0.7.9)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en_core_web_sm) (0.1.0)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en_core_web_sm) (8.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en_core_web_sm) (2.1.3)\r\n",
      "Installing collected packages: pt-core-news-sm\r\n",
      "Successfully installed pt-core-news-sm-3.6.0\r\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\r\n"
     ]
    }
   ],
   "source": [
    "# importando as libs que vamos usar\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy as cp\n",
    "import joblib\n",
    "\n",
    "!python -m nltk.downloader popular \n",
    "!python -m spacy download pt_core_news_sm en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e31c6d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T01:50:45.635007Z",
     "iopub.status.busy": "2023-08-29T01:50:45.633251Z",
     "iopub.status.idle": "2023-08-29T01:50:46.631688Z",
     "shell.execute_reply": "2023-08-29T01:50:46.629379Z"
    },
    "papermill": {
     "duration": 1.01211,
     "end_time": "2023-08-29T01:50:46.634675",
     "exception": false,
     "start_time": "2023-08-29T01:50:45.622565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Usando NLTK (Natural Language Toolkit)\n",
      "----------------------------------------\n",
      "POS tags\n",
      "----------------------------------------\n",
      "[(\"''\", 'N'), ('Vê', 'V'), ('V', 'V'), ('.', '.'), ('Exa.', 'N'), (',', ','), ('Sr.', 'N'), ('presidente', 'N'), (',', ','), ('que', 'PRO-KS-REL'), ('nesse', 'V'), ('tempo', 'N'), (',', ','), ('o', 'ART'), ('nobre', 'ADJ'), ('deputado', 'N'), ('era', 'V'), ('inimigo', 'ADJ'), ('de', 'PREP'), ('todas', 'PROADJ'), ('as', 'ART'), ('leis', 'N'), ('opressoras', 'N'), ('.', '.'), ('A', 'ART'), ('assembléia', 'N'), ('tem', 'VAUX'), ('visto', 'PCP'), ('como', 'KS'), ('ele', 'PROPESS'), ('trata', 'V'), ('as', 'ART'), ('leis', 'NPROP'), ('do', 'NPROP'), ('metro.', 'NPROP'), ('”', 'N'), ('Todo', 'PROADJ'), ('o', 'ART'), ('resto', 'N'), ('do', 'KS'), ('discurso', 'N'), ('foi', 'V'), ('assim', 'ADV'), ('.', '.'), ('A', 'ART'), ('minoria', 'N'), ('protestou', 'V'), ('.', '.'), ('Luís', 'NPROP'), ('Tinoco', 'NPROP'), ('fez-se', 'NPROP'), ('de', 'NPROP'), ('todas', 'PROADJ'), ('as', 'ART'), ('cores', 'N'), (',', ','), ('e', 'KC'), ('a', 'ART'), ('sessão', 'N'), ('acabou', 'V'), ('em', 'PREP'), ('risada', 'N'), ('.', '.'), ('No', 'KC'), ('dia', 'N'), ('seguinte', 'ADJ'), ('os', 'ART'), ('jornais', 'N'), ('amigos', 'ADJ'), ('de', 'PREP'), ('Luís', 'NPROP'), ('Tinoco', 'NPROP'), ('agradeceram', 'V'), ('ao', 'PREP'), ('adversário', 'N'), ('deste', 'N'), ('o', 'ART'), ('triunfo', 'N'), ('que', 'PRO-KS-REL'), ('lhe', 'PROPESS'), ('proporcionou', 'V'), ('mostrando', 'V'), ('à', 'PREP'), ('província', 'N'), ('“', 'N'), ('uma', 'ART'), ('antiga', 'ADJ'), ('e', 'KC'), ('brilhante', 'ADJ'), ('face', 'N'), ('do', 'KS'), ('talento', 'N'), ('do', 'KS'), ('ilustre', 'ADJ'), ('deputado', 'N'), ('”', 'N'), ('.', '.'), ('Os', 'PROSUB'), ('que', 'PRO-KS-REL'), ('indecorosamente', 'ADV'), ('riram', 'V'), ('dos', 'NPROP'), ('versos', 'N'), (',', ','), ('foram', 'VAUX'), ('condenados', 'PCP'), ('com', 'PREP'), ('estas', 'PROADJ'), ('poucas', 'PROADJ'), ('linhas', 'N'), (':', ':'), ('“', 'N'), ('Há', 'V'), ('dias', 'N'), ('um', 'ART'), ('deputado', 'N'), ('governista', 'N'), ('disse', 'V'), ('que', 'KS'), ('a', 'ART'), ('situação', 'N'), ('era', 'V'), ('uma', 'ART'), ('caravana', 'N'), ('de', 'PREP'), ('homens', 'N'), ('honestos', 'ADJ'), ('e', 'KC'), ('bons', 'ADJ'), ('.', '.'), ('É', 'V'), ('caravana', 'N'), (',', ','), ('não', 'ADV'), ('há', 'V'), ('dúvida', 'N'), (';', ';'), ('vimos', 'V'), ('ontem', 'ADV'), ('os', 'ART'), ('seus', 'PROADJ'), ('camelos', 'N'), ('”', 'N'), ('.', '.'), ('Nem', 'ADV'), ('por', 'PREP|+'), ('isso', 'PROSUB'), (',', ','), ('Luís', 'NPROP'), ('Tinoco', 'NPROP'), ('ficou', 'V'), ('mais', 'ADV'), ('consolado', 'PCP'), ('.', '.'), ('As', 'ART'), ('cartas', 'N'), ('ao', 'PREP'), ('Dr.', 'NPROP'), ('Lemos', 'NPROP'), ('começaram', 'V'), ('a', 'PREP'), ('escassear', 'V'), (',', ','), ('até', 'PREP'), ('que', 'PRO-KS-REL'), ('de', 'PREP'), ('todo', 'PROSUB'), ('cessaram', 'V'), ('de', 'PREP'), ('aparecer', 'V'), ('.', '.'), ('Decorreram', 'V'), ('assim', 'ADV'), ('silenciosos', 'ADJ'), ('uns', 'ART'), ('três', 'N'), ('anos', 'N'), (',', ','), ('ao', 'PREP'), ('cabo', 'N'), ('dos', 'N'), ('quais', 'PRO-KS'), ('o', 'ART'), ('Dr.', 'NPROP'), ('Lemos', 'NPROP'), ('foi', 'VAUX'), ('nomeado', 'PCP'), ('não', 'ADV'), ('sei', 'V'), ('para', 'PREP'), ('que', 'KS'), ('cargo', 'N'), ('na', 'ADV'), ('província', 'N'), ('onde', 'ADV-KS-REL'), ('se', 'PROPESS'), ('achava', 'V'), ('Luís', 'NPROP'), ('Tinoco', 'NPROP'), ('.', 'NPROP'), ('Partiu', 'V'), ('.', '.'), ('Apenas', 'PDEN'), ('empossado', 'PCP'), ('do', 'KS'), ('cargo', 'N'), (',', ','), ('tratou', 'V'), ('de', 'PREP'), ('procurar', 'V'), ('o', 'ART'), ('ex-poeta', 'N'), (',', ','), ('e', 'KC'), ('pouco', 'ADV'), ('tempo', 'ADV'), ('gastou', 'V'), ('recebendo', 'V'), ('logo', 'ADV'), ('um', 'ART'), ('convite', 'N'), ('dele', 'NPROP'), ('para', 'PREP'), ('ir', 'V'), ('a', 'PREP'), ('um', 'ART'), ('estabelecimento', 'N'), ('rural', 'ADJ'), ('onde', 'ADV-KS-REL'), ('se', 'PROPESS'), ('achava', 'V'), ('.', '.'), ('–', 'N'), ('Há', 'V'), ('de', 'PREP'), ('me', 'PROPESS'), ('chamar', 'V'), ('ingrato', 'N'), (',', ','), ('não', 'ADV'), ('?', '?'), ('disse', 'V'), ('Luís', 'NPROP'), ('Tinoco', 'NPROP'), (',', ','), ('apenas', 'PDEN'), ('viu', 'V'), ('assomar', 'V'), ('à', 'PREP'), ('porta', 'N'), ('de', 'PREP'), ('casa', 'N'), ('o', 'ART'), ('Dr.', 'NPROP'), ('Lemos', 'NPROP'), ('.', 'NPROP'), ('Mas', 'KC'), ('não', 'ADV'), ('sou', 'V'), (';', ';'), ('contava', 'V'), ('ir', 'V'), ('vê-lo', 'NPROP'), ('daqui', 'PREP'), ('a', 'PREP'), ('um', 'NUM'), ('ano', 'N'), (';', ';'), ('e', 'KC'), ('se', 'KS'), ('lhe', 'PROPESS'), ('não', 'ADV'), ('escrevi…', 'N'), ('Mas', 'KC'), ('que', 'KS'), ('tem', 'V'), ('doutor', 'N'), ('?', '?'), ('está', 'V'), ('espantado', 'PCP'), ('?', '?'), ('O', 'ART'), ('Dr.', 'NPROP'), ('Lemos', 'NPROP'), ('estava', 'V'), ('efetivamente', 'ADV'), ('pasmado', 'PCP'), ('a', 'ART'), ('olhar', 'N'), ('para', 'PREP'), ('a', 'ART'), ('figura', 'N'), ('de', 'PREP'), ('Luís', 'NPROP'), ('Tinoco', 'NPROP'), ('.', 'NPROP'), ('Era', 'V'), ('aquele', 'PROSUB'), ('o', 'PRO-KS'), ('poeta', 'N'), ('dos', 'N'), ('Goivos', 'N'), ('e', 'KC'), ('Camélias', 'N'), (',', ','), ('o', 'ART'), ('eloqüente', 'ADV'), ('deputado', 'N'), (',', ','), ('o', 'ART'), ('fogoso', 'ADJ'), ('publicista', 'N'), ('?', '?'), ('O', 'PROSUB'), ('que', 'PROSUB'), ('ele', 'PROPESS'), ('tinha', 'V'), ('diante', 'PREP'), ('de', 'PREP'), ('si', 'PROPESS'), ('era', 'V'), ('um', 'ART'), ('honrado', 'NPROP'), ('e', 'KC'), ('pacato', 'ADJ'), ('lavrador', 'N'), (',', ','), ('ar', 'N'), ('e', 'KC'), ('maneiras', 'N'), ('rústicas', 'N'), (',', ','), ('sem', 'PREP'), ('o', 'ART'), ('menor', 'ADJ'), ('vestígio', 'N'), ('das', 'NPROP'), ('atitudes', 'N'), ('melancólicas', 'ADJ'), ('do', 'KS'), ('poeta', 'N'), (',', ','), ('do', 'KS'), ('gesto', 'N'), ('arrebatado', 'PCP'), ('do', 'KS'), ('trbuno', 'N'), (',', ','), ('–', 'N'), ('uma', 'ART'), ('transformação', 'N'), (',', ','), ('uma', 'ART'), ('criatura', 'N'), ('muito', 'ADV'), ('outra', 'PROADJ'), ('e', 'KC'), ('muito', 'ADV'), ('melhor', 'ADJ'), ('.', '.'), ('Riram-se', 'NPROP'), ('ambos', 'PROSUB'), (',', ','), ('um', 'ART'), ('da', 'NPROP'), ('mudança', 'N'), (',', ','), ('outro', 'PROADJ'), ('do', 'KS'), ('espanto', 'N'), (',', ','), ('pedindo', 'V'), ('o', 'ART'), ('Dr.', 'NPROP'), ('Lemos', 'NPROP'), ('a', 'ART'), ('Luís', 'NPROP'), ('Tinoco', 'NPROP'), ('lhe', 'PROPESS'), ('dissesse', 'V'), ('se', 'PROPESS'), ('era', 'V'), ('certo', 'ADJ'), ('haver', 'VAUX'), ('deixado', 'PCP'), ('a', 'ART'), ('política', 'N'), (',', ','), ('ou', 'KC'), ('se', 'PROPESS'), ('aquilo', 'PROSUB'), ('eram', 'V'), ('apenas', 'PDEN'), ('umas', 'ART'), ('férias', 'N'), ('para', 'PREP'), ('renovar', 'V'), ('a', 'ART'), ('alma', 'N'), ('.', '.'), ('–', 'N'), ('Tudo', 'NPROP'), ('lhe', 'PROPESS'), ('explicarei', 'V'), (',', ','), ('doutor', 'N'), (',', ','), ('mas', 'KC'), ('há', 'VAUX'), ('de', 'PREP'), ('ser', 'V'), ('depois', 'PREP'), ('de', 'PREP'), ('ter', 'VAUX'), ('examinado', 'PCP'), ('a', 'PREP'), ('minha', 'PROADJ'), ('casa', 'N'), ('e', 'KC'), ('minha', 'PROSUB'), ('roça', 'V'), (',', ','), ('depois', 'PREP'), ('de', 'PREP'), ('lhe', 'PROPESS'), ('apresentar', 'V'), ('minha', 'PROADJ'), ('mulher', 'N'), ('e', 'KC'), ('meus', 'PROADJ'), ('filhos…', 'N'), ('–', 'N'), ('Casado', 'PCP'), ('?', '?'), ('–', 'N'), ('Há', 'V'), ('vinte', 'NUM'), ('meses', 'N'), ('.', '.'), ('–', 'N'), ('E', 'KC'), ('não', 'ADV'), ('me', 'PROPESS'), ('disse', 'V'), ('nada', 'PROSUB'), ('!', '!'), ('–', 'N'), ('Ia', 'IN'), ('este', 'PROADJ'), ('ano', 'N'), ('à', 'PREP'), ('corte', 'N'), ('e', 'KC'), ('esperava', 'V'), ('surpreendê-lo…', 'N'), ('Que', 'KS'), ('duas', 'NUM'), ('criancinhas', 'N'), ('as', 'ART'), ('minhas…', 'N'), ('lindas', 'N'), ('como', 'PREP'), ('dois', 'NUM'), ('anjos', 'N'), ('.', '.'), ('Saem', 'V'), ('à', 'PREP'), ('mãe', 'N'), (',', ','), ('que', 'PRO-KS-REL'), ('é', 'V'), ('a', 'ART'), ('flor', 'N'), ('da', 'N'), ('província', 'N'), ('.', '.'), ('Oxalá', 'IN'), ('pareçam', 'V'), ('também', 'PDEN'), ('com', 'PREP'), ('ela', 'PROPESS'), ('nas', 'NPROP'), ('qualidades', 'NPROP'), ('de', 'PREP'), ('dona', 'N'), ('de', 'PREP'), ('casa', 'N'), (';', ';'), ('que', 'KS'), ('atividade', 'N'), ('!', '!'), ('que', 'PRO-KS-REL'), ('economia', 'N'), ('!', '!'), ('…', 'N'), ('Feita', 'PCP'), ('a', 'ART'), ('apresentação', 'N'), (',', ','), ('beijadas', 'PCP'), ('as', 'ART'), ('crianças', 'N'), (',', ','), ('examinado', 'PCP'), ('tudo', 'PROSUB'), (',', ','), ('Luís', 'NPROP'), ('Tinoco', 'NPROP'), ('declarou', 'V'), ('ao', 'PREP'), ('Dr.', 'NPROP'), ('Lemos', 'NPROP'), ('que', 'PRO-KS-REL'), ('definitivamente', 'ADV'), ('deixara', 'V'), ('a', 'ART'), ('política', 'N'), ('.', '.'), ('–', 'N'), ('De', 'PREP|+'), ('vez', 'PREP|+'), ('?', '?'), ('–', 'N'), ('De', 'PREP|+'), ('vez', 'PREP|+'), ('.', '.'), ('–', 'N'), ('Mas', 'KC'), ('que', 'KS'), ('motivo', 'N'), ('?', '?'), ('desgostos', 'N'), (',', ','), ('naturalmente', 'ADV'), ('.', '.'), ('–', 'N'), ('Não', 'ADV'), (';', ';'), ('descobri', 'V'), ('que', 'KS'), ('não', 'ADV'), ('era', 'V'), ('fadado', 'PCP'), ('para', 'PREP'), ('grandes', 'ADJ'), ('destinos', 'N'), ('.', '.'), ('Um', 'ART'), ('dia', 'N'), ('leram-me', 'NPROP'), ('na', 'NPROP'), ('assembléia', 'N'), ('alguns', 'PROADJ'), ('versos', 'N'), ('meus', 'PROADJ'), ('.', '.'), ('Reconheci', 'V'), ('então', 'ADV'), ('quanto', 'KC'), ('eram', 'V'), ('pífios', 'N'), ('os', 'ART'), ('tais', 'PROADJ'), ('versos', 'N'), (';', ';'), ('e', 'KC'), ('podendo', 'VAUX'), ('vir', 'V'), ('mais', 'ADV'), ('tarde', 'ADV'), ('a', 'ART'), ('olhar', 'N'), ('com', 'PREP'), ('a', 'ART'), ('mesma', 'PROADJ'), ('lástima', 'N'), ('e', 'KC'), ('igual', 'ADJ'), ('arrependimento', 'N'), ('para', 'PREP'), ('as', 'ART'), ('minhas', 'PROADJ'), ('obras', 'N'), ('políticas', 'ADJ'), (',', ','), ('arrepiei', 'V'), ('carreira', 'N'), ('e', 'KC'), ('deixei', 'V'), ('a', 'ART'), ('vida', 'N'), ('pública', 'ADJ'), ('.', '.'), ('Uma', 'ART'), ('noite', 'N'), ('de', 'PREP'), ('reflexão', 'N'), ('e', 'KC'), ('nada', 'PROSUB'), ('mais', 'ADV'), ('.', '.'), ('–', 'N'), ('Pois', 'KC'), ('teve', 'V'), ('ânimo', 'N'), ('?', '?'), ('…', 'N'), ('–', 'N'), ('Tive', 'V'), (',', ','), ('meu', 'PROADJ'), ('amigo', 'N'), (',', ','), ('tive', 'V'), ('ânimo', 'N'), ('de', 'PREP'), ('pisar', 'V'), ('terreno', 'N'), ('sólido', 'ADJ'), (',', ','), ('em', 'PREP'), ('vez', 'PREP'), ('de', 'PREP'), ('patinhar', 'V'), ('nas', 'NPROP'), ('ilusões', 'N'), ('dos', 'N'), ('primeiros', 'ADJ'), ('dias', 'N'), ('.', '.'), ('Eu', 'PROPESS'), ('era', 'V'), ('um', 'ART'), ('ridículo', 'N'), ('poeta', 'N'), ('e', 'KC'), ('talvez', 'PDEN'), ('ainda', 'ADV'), ('mais', 'ADV'), ('ridículo', 'ADJ'), ('orador', 'N'), ('.', '.'), ('Minha', 'PROADJ'), ('vocação', 'N'), ('era', 'V'), ('esta', 'PROADJ'), ('.', '.'), ('Com', 'PREP'), ('poucos', 'PROADJ'), ('anos', 'N'), ('mais', 'ADV'), ('estou', 'V'), ('rico', 'ADJ'), ('.', '.'), ('Ande', 'N'), ('agora', 'ADV'), ('beber', 'V'), ('o', 'ART'), ('café', 'N'), ('que', 'PRO-KS-REL'), ('nos', 'PROPESS'), ('espera', 'V'), ('e', 'KC'), ('feche', 'V'), ('a', 'ART'), ('boca', 'N'), (',', ','), ('que', 'PRO-KS-REL'), ('as', 'PROPESS'), ('moscas', 'N'), ('andam', 'V'), ('no', 'KC'), ('ar', 'N'), ('.', '.')]\n",
      "----------------------------------------\n",
      "POS tags (em dataframe)\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>664</th>\n",
       "      <th>665</th>\n",
       "      <th>666</th>\n",
       "      <th>667</th>\n",
       "      <th>668</th>\n",
       "      <th>669</th>\n",
       "      <th>670</th>\n",
       "      <th>671</th>\n",
       "      <th>672</th>\n",
       "      <th>673</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>''</td>\n",
       "      <td>Vê</td>\n",
       "      <td>V</td>\n",
       "      <td>.</td>\n",
       "      <td>Exa.</td>\n",
       "      <td>,</td>\n",
       "      <td>Sr.</td>\n",
       "      <td>presidente</td>\n",
       "      <td>,</td>\n",
       "      <td>que</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>boca</td>\n",
       "      <td>,</td>\n",
       "      <td>que</td>\n",
       "      <td>as</td>\n",
       "      <td>moscas</td>\n",
       "      <td>andam</td>\n",
       "      <td>no</td>\n",
       "      <td>ar</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>,</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>,</td>\n",
       "      <td>PRO-KS-REL</td>\n",
       "      <td>...</td>\n",
       "      <td>ART</td>\n",
       "      <td>N</td>\n",
       "      <td>,</td>\n",
       "      <td>PRO-KS-REL</td>\n",
       "      <td>PROPESS</td>\n",
       "      <td>N</td>\n",
       "      <td>V</td>\n",
       "      <td>KC</td>\n",
       "      <td>N</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 674 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  0   1   2   3     4   5    6           7   8           9    ...  664   665  \\\n",
       "0  ''  Vê   V   .  Exa.   ,  Sr.  presidente   ,         que  ...    a  boca   \n",
       "1   N   V   V   .     N   ,    N           N   ,  PRO-KS-REL  ...  ART     N   \n",
       "\n",
       "  666         667      668     669    670 671 672 673  \n",
       "0   ,         que       as  moscas  andam  no  ar   .  \n",
       "1   ,  PRO-KS-REL  PROPESS       N      V  KC   N   .  \n",
       "\n",
       "[2 rows x 674 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry = '''\n",
    "\"Vê V. Exa., Sr. presidente, que nesse tempo, o nobre deputado era inimigo de todas as leis opressoras. A assembléia tem visto como ele trata as leis do metro.” Todo o resto do discurso foi assim. A minoria protestou. Luís Tinoco fez-se de todas as cores, e a sessão acabou em risada. No dia seguinte os jornais amigos de Luís Tinoco agradeceram ao adversário deste o triunfo que lhe proporcionou mostrando à província “uma antiga e brilhante face do talento do ilustre deputado”. Os que indecorosamente riram dos versos, foram condenados com estas poucas linhas: “Há dias um deputado governista disse que a situação era uma caravana de homens honestos e bons. É caravana, não há dúvida; vimos ontem os seus camelos”.\n",
    "Nem por isso, Luís Tinoco ficou mais consolado. As cartas ao Dr. Lemos começaram a escassear, até que de todo cessaram de aparecer. Decorreram assim silenciosos uns três anos, ao cabo dos quais o Dr. Lemos foi nomeado não sei para que cargo na província onde se achava Luís Tinoco. Partiu.\n",
    "Apenas empossado do cargo, tratou de procurar o ex-poeta, e pouco tempo gastou recebendo logo um convite dele para ir a um estabelecimento rural onde se achava.\n",
    "– Há de me chamar ingrato, não? disse Luís Tinoco, apenas viu assomar à porta de casa o Dr. Lemos. Mas não sou; contava ir vê-lo daqui a um ano; e se lhe não escrevi… Mas que tem doutor? está espantado? O Dr. Lemos estava efetivamente pasmado a olhar para a figura de Luís Tinoco. Era aquele o poeta dos Goivos e Camélias, o eloqüente deputado, o fogoso publicista? O que ele tinha diante de si era um honrado e pacato lavrador, ar e maneiras rústicas, sem o menor vestígio das atitudes melancólicas do poeta, do gesto arrebatado do trbuno, – uma transformação, uma criatura muito outra e muito melhor.\n",
    "Riram-se ambos, um da mudança, outro do espanto, pedindo o Dr. Lemos a Luís Tinoco lhe dissesse se era certo haver deixado a política, ou se aquilo eram apenas umas férias para renovar a alma.\n",
    "– Tudo lhe explicarei, doutor, mas há de ser depois de ter examinado a minha casa e minha roça, depois de lhe apresentar minha mulher e meus filhos…\n",
    "– Casado? – Há vinte meses.\n",
    "– E não me disse nada! – Ia este ano à corte e esperava surpreendê-lo… Que duas criancinhas as minhas… lindas como dois anjos. Saem à mãe, que é a flor da província. Oxalá pareçam também com ela nas qualidades de dona de casa; que atividade! que economia!…\n",
    "Feita a apresentação, beijadas as crianças, examinado tudo, Luís Tinoco declarou ao Dr. Lemos que definitivamente deixara a política.\n",
    "– De vez? – De vez.\n",
    "– Mas que motivo? desgostos, naturalmente.\n",
    "– Não; descobri que não era fadado para grandes destinos. Um dia leram-me na assembléia alguns versos meus. Reconheci então quanto eram pífios os tais versos; e podendo vir mais tarde a olhar com a mesma lástima e igual arrependimento para as minhas obras políticas, arrepiei carreira e deixei a vida pública. Uma noite de reflexão e nada mais.\n",
    "– Pois teve ânimo?…\n",
    "– Tive, meu amigo, tive ânimo de pisar terreno sólido, em vez de patinhar nas ilusões dos primeiros dias. Eu era um ridículo poeta e talvez ainda mais ridículo orador. Minha vocação era esta.\n",
    "Com poucos anos mais estou rico. Ande agora beber o café que nos espera e feche a boca, que as moscas andam no ar.\n",
    "'''\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Usando NLTK (Natural Language Toolkit)\")\n",
    "# Referência para pegar o modelo treinado: https://github.com/inoueMashuu/POS-tagger-portuguese-nltk\n",
    "trained_data = \"../input/pos-tagger-brill/POS_tagger_brill.pkl\"\n",
    "portuguese_tagger = joblib.load(trained_data)\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(\"POS tags\")\n",
    "print(\"----------------------------------------\")\n",
    "pos_tags_nltk = portuguese_tagger.tag(nltk.word_tokenize(entry))\n",
    "print(pos_tags_nltk)\n",
    "print(\"----------------------------------------\")\n",
    "print(\"POS tags (em dataframe)\")\n",
    "print(\"----------------------------------------\")\n",
    "pos_tags_nltk_df = pd.DataFrame(pos_tags_nltk).T\n",
    "pos_tags_nltk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0db6d14",
   "metadata": {
    "papermill": {
     "duration": 0.008681,
     "end_time": "2023-08-29T01:50:46.652549",
     "exception": false,
     "start_time": "2023-08-29T01:50:46.643868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2. Exemplifique a stemização e a lematização de um texto, em língua portuguesa. Ilustre um caso onde textos diferentes conduzem a uma mesma saída através do stemming ou lemmatization. Considere como saída um vetor ordenado contendo lemas e stems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed7689b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T01:50:46.672436Z",
     "iopub.status.busy": "2023-08-29T01:50:46.671999Z",
     "iopub.status.idle": "2023-08-29T01:50:47.950450Z",
     "shell.execute_reply": "2023-08-29T01:50:47.948868Z"
    },
    "papermill": {
     "duration": 1.291931,
     "end_time": "2023-08-29T01:50:47.953546",
     "exception": false,
     "start_time": "2023-08-29T01:50:46.661615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Primeira entrada: Proponho descansar\n",
      "----------------------------------------\n",
      "stemming: ['proponho', 'descans']\n",
      "lemmatization: ['Proponho', 'descansar']\n",
      "----------------------------------------\n",
      "Segunda entrada: Propus descansar\n",
      "----------------------------------------\n",
      "stemming: ['propus', 'descans']\n",
      "lemmatization: ['propus', 'descansar']\n"
     ]
    }
   ],
   "source": [
    "entry_1 = \"Proponho descansar\"\n",
    "entry_2 = \"Propus descansar\"\n",
    "\n",
    "stemmer = nltk.SnowballStemmer(\"portuguese\")\n",
    "model_spacy = spacy.load('pt_core_news_sm')\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print('Primeira entrada:', entry_1)\n",
    "print(\"----------------------------------------\")\n",
    "print('stemming:', stemmer.stem(entry_1).split()) \n",
    "print('lemmatization:', [ word.lemma_ for word in model_spacy(entry_1)])\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print('Segunda entrada:', entry_2)\n",
    "print(\"----------------------------------------\")\n",
    "print('stemming:', stemmer.stem(entry_2).split())\n",
    "print('lemmatization:', [word.lemma_ for word in model_spacy(entry_2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e8327c",
   "metadata": {
    "papermill": {
     "duration": 0.009206,
     "end_time": "2023-08-29T01:50:47.972019",
     "exception": false,
     "start_time": "2023-08-29T01:50:47.962813",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "3. Repita 1 considerando a língua inglesa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa1e1f11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T01:50:47.992541Z",
     "iopub.status.busy": "2023-08-29T01:50:47.992083Z",
     "iopub.status.idle": "2023-08-29T01:50:49.515803Z",
     "shell.execute_reply": "2023-08-29T01:50:49.514375Z"
    },
    "papermill": {
     "duration": 1.537117,
     "end_time": "2023-08-29T01:50:49.518343",
     "exception": false,
     "start_time": "2023-08-29T01:50:47.981226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Usando SpaCy\n",
      "----------------------------------------\n",
      "POS tags\n",
      "----------------------------------------\n",
      "[('\"', 'PUNCT'), ('The', 'DET'), ('Selection', 'PROPN'), ('\"', 'PUNCT'), ('is', 'AUX'), ('a', 'DET'), ('book', 'NOUN'), ('series', 'NOUN'), ('written', 'VERB'), ('by', 'ADP'), ('Kiera', 'PROPN'), ('Cass', 'PROPN'), (',', 'PUNCT'), ('consisting', 'VERB'), ('of', 'ADP'), ('five', 'NUM'), ('volumes', 'NOUN'), (':', 'PUNCT'), ('\"', 'PUNCT'), ('The', 'DET'), ('Selection', 'PROPN'), (',', 'PUNCT'), ('\"', 'PUNCT'), ('\"', 'PUNCT'), ('The', 'DET'), ('Elite', 'PROPN'), (',', 'PUNCT'), ('\"', 'PUNCT'), ('\"', 'PUNCT'), ('The', 'DET'), ('One', 'NUM'), (',', 'PUNCT'), ('\"', 'PUNCT'), ('\"', 'PUNCT'), ('The', 'DET'), ('Heir', 'PROPN'), (',', 'PUNCT'), ('\"', 'PUNCT'), ('and', 'CCONJ'), ('\"', 'PUNCT'), ('The', 'DET'), ('Crown', 'PROPN'), ('.', 'PUNCT'), ('\"', 'PUNCT'), ('The', 'DET'), ('story', 'NOUN'), ('takes', 'VERB'), ('place', 'NOUN'), ('in', 'ADP'), ('a', 'DET'), ('dystopian', 'ADJ'), ('future', 'NOUN'), ('where', 'SCONJ'), ('a', 'DET'), ('young', 'ADJ'), ('woman', 'NOUN'), ('named', 'VERB'), ('America', 'PROPN'), ('Singer', 'PROPN'), ('is', 'AUX'), ('selected', 'VERB'), ('to', 'PART'), ('participate', 'VERB'), ('in', 'ADP'), ('a', 'DET'), ('competition', 'NOUN'), ('to', 'PART'), ('determine', 'VERB'), ('who', 'PRON'), ('will', 'AUX'), ('become', 'VERB'), ('the', 'DET'), ('future', 'ADJ'), ('wife', 'NOUN'), ('of', 'ADP'), ('Prince', 'PROPN'), ('Maxon', 'PROPN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('One', 'NUM'), ('of', 'ADP'), ('the', 'DET'), ('standout', 'NOUN'), ('features', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('series', 'NOUN'), ('is', 'AUX'), ('the', 'DET'), ('combination', 'NOUN'), ('of', 'ADP'), ('dystopian', 'ADJ'), ('and', 'CCONJ'), ('romance', 'NOUN'), ('elements', 'NOUN'), (',', 'PUNCT'), ('which', 'PRON'), ('has', 'AUX'), ('attracted', 'VERB'), ('many', 'ADJ'), ('readers', 'NOUN'), ('.', 'PUNCT'), ('The', 'DET'), ('premise', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('competition', 'NOUN'), ('to', 'PART'), ('become', 'VERB'), ('the', 'DET'), ('princess', 'NOUN'), ('and', 'CCONJ'), ('the', 'DET'), ('dynamics', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('romantic', 'ADJ'), ('relationships', 'NOUN'), ('between', 'ADP'), ('the', 'DET'), ('characters', 'NOUN'), ('are', 'AUX'), ('central', 'ADJ'), ('to', 'ADP'), ('the', 'DET'), ('plot', 'NOUN'), ('.', 'PUNCT'), ('The', 'DET'), ('storyline', 'NOUN'), ('presents', 'VERB'), ('a', 'DET'), ('complex', 'ADJ'), ('social', 'ADJ'), ('context', 'NOUN'), (',', 'PUNCT'), ('where', 'SCONJ'), ('society', 'NOUN'), ('is', 'AUX'), ('divided', 'VERB'), ('into', 'ADP'), ('castes', 'NOUN'), (',', 'PUNCT'), ('creating', 'VERB'), ('tensions', 'NOUN'), ('and', 'CCONJ'), ('conflicts', 'NOUN'), ('that', 'PRON'), ('unfold', 'VERB'), ('throughout', 'ADP'), ('the', 'DET'), ('narrative', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('The', 'DET'), ('main', 'ADJ'), ('characters', 'NOUN'), ('are', 'AUX'), ('well', 'ADV'), ('-', 'PUNCT'), ('developed', 'VERB'), (',', 'PUNCT'), ('with', 'ADP'), ('distinct', 'ADJ'), ('traits', 'NOUN'), ('and', 'CCONJ'), ('varied', 'ADJ'), ('personalities', 'NOUN'), ('.', 'PUNCT'), ('America', 'PROPN'), ('Singer', 'PROPN'), (',', 'PUNCT'), ('the', 'DET'), ('protagonist', 'NOUN'), (',', 'PUNCT'), ('is', 'AUX'), ('a', 'DET'), ('captivating', 'VERB'), ('character', 'NOUN'), ('with', 'ADP'), ('a', 'DET'), ('strong', 'ADJ'), ('and', 'CCONJ'), ('determined', 'ADJ'), ('voice', 'NOUN'), ('.', 'PUNCT'), ('Prince', 'PROPN'), ('Maxon', 'PROPN'), ('is', 'AUX'), ('portrayed', 'VERB'), ('as', 'ADP'), ('a', 'DET'), ('benevolent', 'ADJ'), ('leader', 'NOUN'), ('who', 'PRON'), ('is', 'AUX'), ('genuinely', 'ADV'), ('interested', 'ADJ'), ('in', 'ADP'), ('finding', 'VERB'), ('a', 'DET'), ('true', 'ADJ'), ('partner', 'NOUN'), ('.', 'PUNCT'), ('The', 'DET'), ('supporting', 'VERB'), ('characters', 'NOUN'), ('also', 'ADV'), ('have', 'VERB'), ('their', 'PRON'), ('own', 'ADJ'), ('stories', 'NOUN'), ('and', 'CCONJ'), ('contribute', 'VERB'), ('to', 'ADP'), ('the', 'DET'), ('plot', 'NOUN'), ('in', 'ADP'), ('different', 'ADJ'), ('ways', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('Kiera', 'PROPN'), ('Cass', 'PROPN'), (\"'s\", 'PART'), ('writing', 'NOUN'), ('is', 'AUX'), ('accessible', 'ADJ'), ('and', 'CCONJ'), ('fluid', 'ADJ'), (',', 'PUNCT'), ('making', 'VERB'), ('the', 'DET'), ('reading', 'NOUN'), ('experience', 'NOUN'), ('engaging', 'ADJ'), ('and', 'CCONJ'), ('easy', 'ADJ'), ('to', 'PART'), ('follow', 'VERB'), ('.', 'PUNCT'), ('The', 'DET'), ('author', 'NOUN'), ('builds', 'VERB'), ('a', 'DET'), ('detailed', 'ADJ'), ('world', 'NOUN'), ('and', 'CCONJ'), ('effectively', 'ADV'), ('conveys', 'VERB'), ('the', 'DET'), ('characters', 'NOUN'), (\"'\", 'PART'), ('emotions', 'NOUN'), ('.', 'PUNCT'), ('The', 'DET'), ('series', 'NOUN'), ('also', 'ADV'), ('addresses', 'VERB'), ('themes', 'NOUN'), ('such', 'ADJ'), ('as', 'ADP'), ('politics', 'NOUN'), (',', 'PUNCT'), ('social', 'ADJ'), ('inequality', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('the', 'DET'), ('power', 'NOUN'), ('of', 'ADP'), ('love', 'NOUN'), ('and', 'CCONJ'), ('friendship', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('However', 'ADV'), (',', 'PUNCT'), ('some', 'DET'), ('critics', 'NOUN'), ('argue', 'VERB'), ('that', 'SCONJ'), ('\"', 'PUNCT'), ('The', 'DET'), ('Selection', 'PROPN'), ('\"', 'PUNCT'), ('series', 'NOUN'), ('can', 'AUX'), ('be', 'AUX'), ('considered', 'VERB'), ('predictable', 'ADJ'), ('and', 'CCONJ'), ('includes', 'VERB'), ('some', 'DET'), ('character', 'NOUN'), ('stereotypes', 'NOUN'), ('.', 'PUNCT'), ('Additionally', 'ADV'), (',', 'PUNCT'), ('some', 'DET'), ('elements', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('plot', 'NOUN'), ('may', 'AUX'), ('seem', 'VERB'), ('clichéd', 'NOUN'), ('to', 'ADP'), ('more', 'ADV'), ('demanding', 'ADJ'), ('readers', 'NOUN'), ('.', 'PUNCT'), ('However', 'ADV'), (',', 'PUNCT'), ('it', 'PRON'), ('is', 'AUX'), ('important', 'ADJ'), ('to', 'PART'), ('note', 'VERB'), ('that', 'SCONJ'), ('the', 'DET'), ('series', 'NOUN'), ('has', 'VERB'), ('a', 'DET'), ('specific', 'ADJ'), ('target', 'NOUN'), ('audience', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('many', 'ADJ'), ('readers', 'NOUN'), ('appreciate', 'VERB'), ('precisely', 'ADV'), ('these', 'DET'), ('aspects', 'NOUN'), ('that', 'PRON'), ('could', 'AUX'), ('be', 'AUX'), ('seen', 'VERB'), ('as', 'ADP'), ('predictable', 'ADJ'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('Overall', 'ADV'), (',', 'PUNCT'), ('\"', 'PUNCT'), ('The', 'DET'), ('Selection', 'PROPN'), ('\"', 'PUNCT'), ('by', 'ADP'), ('Kiera', 'PROPN'), ('Cass', 'PROPN'), ('is', 'AUX'), ('a', 'DET'), ('book', 'NOUN'), ('series', 'NOUN'), ('that', 'PRON'), ('has', 'AUX'), ('gained', 'VERB'), ('a', 'DET'), ('large', 'ADJ'), ('following', 'NOUN'), (',', 'PUNCT'), ('especially', 'ADV'), ('among', 'ADP'), ('younger', 'ADJ'), ('readers', 'NOUN'), ('.', 'PUNCT'), ('With', 'ADP'), ('a', 'DET'), ('blend', 'NOUN'), ('of', 'ADP'), ('romance', 'NOUN'), (',', 'PUNCT'), ('dystopia', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('palace', 'NOUN'), ('intrigue', 'NOUN'), (',', 'PUNCT'), ('the', 'DET'), ('story', 'NOUN'), ('captivates', 'VERB'), ('and', 'CCONJ'), ('entertains', 'NOUN'), (',', 'PUNCT'), ('providing', 'VERB'), ('a', 'DET'), ('light', 'NOUN'), ('and', 'CCONJ'), ('engaging', 'ADJ'), ('read', 'NOUN'), ('.', 'PUNCT'), ('If', 'SCONJ'), ('you', 'PRON'), ('enjoy', 'VERB'), ('young', 'ADJ'), ('adult', 'NOUN'), ('romance', 'NOUN'), ('with', 'ADP'), ('a', 'DET'), ('touch', 'NOUN'), ('of', 'ADP'), ('adventure', 'NOUN'), ('and', 'CCONJ'), ('drama', 'NOUN'), (',', 'PUNCT'), ('\"', 'PUNCT'), ('The', 'DET'), ('Selection', 'PROPN'), ('\"', 'PUNCT'), ('series', 'NOUN'), ('may', 'AUX'), ('be', 'AUX'), ('an', 'DET'), ('interesting', 'ADJ'), ('choice', 'NOUN'), ('for', 'ADP'), ('you', 'PRON'), ('.', 'PUNCT')]\n",
      "----------------------------------------\n",
      "POS tags (em dataframe)\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>409</th>\n",
       "      <th>410</th>\n",
       "      <th>411</th>\n",
       "      <th>412</th>\n",
       "      <th>413</th>\n",
       "      <th>414</th>\n",
       "      <th>415</th>\n",
       "      <th>416</th>\n",
       "      <th>417</th>\n",
       "      <th>418</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"</td>\n",
       "      <td>The</td>\n",
       "      <td>Selection</td>\n",
       "      <td>\"</td>\n",
       "      <td>is</td>\n",
       "      <td>a</td>\n",
       "      <td>book</td>\n",
       "      <td>series</td>\n",
       "      <td>written</td>\n",
       "      <td>by</td>\n",
       "      <td>...</td>\n",
       "      <td>\"</td>\n",
       "      <td>series</td>\n",
       "      <td>may</td>\n",
       "      <td>be</td>\n",
       "      <td>an</td>\n",
       "      <td>interesting</td>\n",
       "      <td>choice</td>\n",
       "      <td>for</td>\n",
       "      <td>you</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PUNCT</td>\n",
       "      <td>DET</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>AUX</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADP</td>\n",
       "      <td>...</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>AUX</td>\n",
       "      <td>AUX</td>\n",
       "      <td>DET</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 419 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1          2      3    4    5     6       7        8    9    ...  \\\n",
       "0      \"  The  Selection      \"   is    a  book  series  written   by  ...   \n",
       "1  PUNCT  DET      PROPN  PUNCT  AUX  DET  NOUN    NOUN     VERB  ADP  ...   \n",
       "\n",
       "     409     410  411  412  413          414     415  416   417    418  \n",
       "0      \"  series  may   be   an  interesting  choice  for   you      .  \n",
       "1  PUNCT    NOUN  AUX  AUX  DET          ADJ    NOUN  ADP  PRON  PUNCT  \n",
       "\n",
       "[2 rows x 419 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_entry = '''\"The Selection\" is a book series written by Kiera Cass, consisting of five volumes: \"The Selection,\" \"The Elite,\" \"The One,\" \"The Heir,\" and \"The Crown.\" The story takes place in a dystopian future where a young woman named America Singer is selected to participate in a competition to determine who will become the future wife of Prince Maxon.\n",
    "One of the standout features of the series is the combination of dystopian and romance elements, which has attracted many readers. The premise of the competition to become the princess and the dynamics of the romantic relationships between the characters are central to the plot. The storyline presents a complex social context, where society is divided into castes, creating tensions and conflicts that unfold throughout the narrative.\n",
    "The main characters are well-developed, with distinct traits and varied personalities. America Singer, the protagonist, is a captivating character with a strong and determined voice. Prince Maxon is portrayed as a benevolent leader who is genuinely interested in finding a true partner. The supporting characters also have their own stories and contribute to the plot in different ways.\n",
    "Kiera Cass's writing is accessible and fluid, making the reading experience engaging and easy to follow. The author builds a detailed world and effectively conveys the characters' emotions. The series also addresses themes such as politics, social inequality, and the power of love and friendship.\n",
    "However, some critics argue that \"The Selection\" series can be considered predictable and includes some character stereotypes. Additionally, some elements of the plot may seem clichéd to more demanding readers. However, it is important to note that the series has a specific target audience, and many readers appreciate precisely these aspects that could be seen as predictable.\n",
    "Overall, \"The Selection\" by Kiera Cass is a book series that has gained a large following, especially among younger readers. With a blend of romance, dystopia, and palace intrigue, the story captivates and entertains, providing a light and engaging read. If you enjoy young adult romance with a touch of adventure and drama, \"The Selection\" series may be an interesting choice for you.'''\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Usando SpaCy\")\n",
    "print(\"----------------------------------------\")\n",
    "print(\"POS tags\")\n",
    "print(\"----------------------------------------\")\n",
    "en_model_spacy = spacy.load('en_core_web_sm') \n",
    "en_pos_tags_spacy = [(word.text, word.pos_) for word in en_model_spacy(en_entry)]\n",
    "print(en_pos_tags_spacy)\n",
    "print(\"----------------------------------------\")\n",
    "print(\"POS tags (em dataframe)\")\n",
    "print(\"----------------------------------------\")\n",
    "en_pos_tags_spacy_df = pd.DataFrame(en_pos_tags_spacy).T\n",
    "en_pos_tags_spacy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ebe0dc",
   "metadata": {
    "papermill": {
     "duration": 0.009482,
     "end_time": "2023-08-29T01:50:49.537777",
     "exception": false,
     "start_time": "2023-08-29T01:50:49.528295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "4. Repita 2 considerando a língua inglesa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95528ea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T01:50:49.561742Z",
     "iopub.status.busy": "2023-08-29T01:50:49.560585Z",
     "iopub.status.idle": "2023-08-29T01:50:50.823169Z",
     "shell.execute_reply": "2023-08-29T01:50:50.821841Z"
    },
    "papermill": {
     "duration": 1.276756,
     "end_time": "2023-08-29T01:50:50.826285",
     "exception": false,
     "start_time": "2023-08-29T01:50:49.549529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Primeira entrada: I work a lot\n",
      "----------------------------------------\n",
      "stemming: ['i', 'work', 'a', 'lot']\n",
      "lemmatization: ['I', 'work', 'a', 'lot']\n",
      "----------------------------------------\n",
      "Segunda entrada: I worked a lot\n",
      "----------------------------------------\n",
      "stemming: ['i', 'work', 'a', 'lot']\n",
      "lemmatization: ['I', 'work', 'a', 'lot']\n"
     ]
    }
   ],
   "source": [
    "en_entry_1 = \"I work a lot\"\n",
    "en_entry_2 = \"I worked a lot\"\n",
    "\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "en_model_spacy = spacy.load('en_core_web_sm')\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print('Primeira entrada:', en_entry_1)\n",
    "print(\"----------------------------------------\")\n",
    "print('stemming:', [stemmer.stem(word) for word in en_entry_1.split()])\n",
    "print('lemmatization:', [word.lemma_ for word in en_model_spacy(en_entry_1)])\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print('Segunda entrada:', en_entry_2)\n",
    "print(\"----------------------------------------\")\n",
    "print('stemming:', [stemmer.stem(word) for word in en_entry_2.split()])\n",
    "print('lemmatization:', [word.lemma_ for word in en_model_spacy(en_entry_2)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 68.842653,
   "end_time": "2023-08-29T01:50:54.157094",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-29T01:49:45.314441",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
