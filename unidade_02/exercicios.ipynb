{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Exercícios: Pré-processamento\nFonte: CARVALHO, Fabrício Galende Marques de. **Notas de aula da disciplina processamento de linguagem natural.** São José dos Campos, 2023.\n\n#### Atividade realizada em grupo: \n- Gabriel Camargo Leite\n- Giovana Thaís de O. Silva\n- Isabelle Dias R. Silva\n- João Marcos O. Santos\n- Maria Gabriela G. S. Reis\n- Thiago Henrique Ferreira","metadata":{}},{"cell_type":"markdown","source":"## Terminologia e conceitos\n---\n\n1.  (TC.2.2) Qual um possível efeito da não remoção de um iframe ou de scripts e CSS’s de um documento capturado através de uma raspagem de dados? \n\n**Resposta:** Conforme consultado no material de aula, caso a remoção de tags, executada depois da raspagem de dados em rede (web scraping), não seja feita, ou seja, se as tags e dados não informativos (scripts, css, iframes…) não forem removidos do texto, é possível que ruídos sejam criados na base de dados a ser utilizada pelas próximas etapas da pipeline, o que poderia influenciar em análises errôneas.\n\n2. (TC.2.4) Cite exemplos de tokens de frases e tokens de palavras que podem significar:\n\n| Situação                                                                          | Token de frase             | Token de palavra |\n|:----------------------------------------------------------------------------------|:---------------------------|:-----------------|\n| Opinião negativa referente a um produto de uma loja de vestuário                  | Tecido ruim                | Largo            |\n| Opinião positiva referente a um produto de uma loja de vestuário                  | Costura muito boa          | Confortável      |\n| Opinião neutra referente a um produto de uma loja de vestuário                    | Veste mais ou menos        | OK               |\n| Opinião negativa relacionada a um carro vendido por uma concessionária automotiva | Câmbio impreciso           | Desalinhado      |\n| Opinião positiva relacionada a um carro vendido por uma concessionária automotiva | Manutenção simples         | Robustez         |\n| Opinião neutra relacionada a um carro vendido por uma concessionária automotiva   | Carro bom, mas gasta muito | Decente          |\n","metadata":{}},{"cell_type":"markdown","source":"## Prática de programação\n---\n\n1. (PP.2.1) Tomando como base o código-fonte fornecido pelo professor e efetuando uma raspagem de dados que opere sobre alguma página contendo revisão de produtos, efetue uma comparação de desempenho utilizando 3 modelos de tokenizadores de sentença. Qual sua conclusão?\n\n> **OBS:** Kaggle não deixa pegar a review do Mercado Livre (proteção contra requisições)","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# Instalação do pacote em Português do Spacy\n# =============================================================================\n!python -m spacy download pt","metadata":{"execution":{"iopub.status.busy":"2023-09-25T23:35:16.467013Z","iopub.execute_input":"2023-09-25T23:35:16.467417Z","iopub.status.idle":"2023-09-25T23:35:35.056373Z","shell.execute_reply.started":"2023-09-25T23:35:16.467386Z","shell.execute_reply":"2023-09-25T23:35:35.054747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from colorama import Fore, Back, Style \nimport requests\nfrom bs4 import BeautifulSoup\nimport time\nfrom transformers import AutoTokenizer\nimport nltk\n#nltk.download('punkt')\nimport spacy\nnlp = spacy.load(\"pt_core_news_sm\")\n\ndef format_time(seconds):\n    if seconds < 1:\n        return f\"{seconds * 1000:.2f} ms\"\n    else:\n        return f\"{seconds:.2f} s\"\n    \ndef spacy_tokenizer(text):\n    doc = nlp(text)\n    tokens = [token.text for token in doc]\n    return tokens\n\n# a function to get rid of html tags\ndef get_rid_html_tags(text):\n    soup = BeautifulSoup(text, \"html.parser\")\n    # iframe and script nodes removal from doc tree\n    [s.extract() for s in soup(['iframe','script'])]\n    stripped_text = soup.get_text()\n    stripped_text = re.sub(r'[\\r|\\n|\\r\\n]','\\n',stripped_text)\n    return stripped_text\n\ndef cus_data(soup):\n    # find the Html tag with find() and convert into string\n    data_str = \"\"\n    cus_list = []\n  \n    for item in soup.find_all(\"p\", class_=\"ui-review-capability-comments__comment__content\"):\n        data_str = data_str + item.get_text()\n        cus_list.append(data_str)\n        data_str = \"\"\n    return cus_list\n\n\ndata = requests.get(\"https://www.mercadolivre.com.br/controle-joystick-sem-fio-sony-playstation-dualsense-edge-branco/p/MLB21286427?pdp_filters=category:MLB455266#reviews\")\n\ncontent = data.content\nsoup = BeautifulSoup(content, \"html.parser\")\n\ncus_res = cus_data(soup)\nprint(\"\\n=============================\\nAvaliações do controle de PS5\\n=============================\\n\")\n\nfor y in range(0, len(cus_res)):\n    print(f'{y+1}: {cus_res[y]}')\n    review_text = cus_res[y]\n    \n    # NLTK_TOKENIZER\n    start_time = time.time()\n    nltk_tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    default_nltk_tokens = nltk_tokenizer.tokenize(review_text)\n    nltk_elapsed_time = time.time() - start_time\n    print(\"=================================================================\")\n\n    print(f'Tokens {Fore.BLUE}NLTK (padrão){Fore.RESET}: {default_nltk_tokens}')\n    print(f'{Fore.GREEN} Tempo de processamento {Fore.BLUE}NLTK (padrão){Fore.GREEN}: {format_time(nltk_elapsed_time)} {Fore.RESET}')\n    print(\"- - - - - - - - - - -\")\n\n    # Tokenizador simples (espaço como delimitador)\n    start_time = time.time()\n    simple_tokens = review_text.split()  # Usando split() diretamente\n    simple_elapsed_time = time.time() - start_time\n\n    print(f'Tokens com {Fore.BLUE}delimitador de espaço{Fore.RESET}: {simple_tokens}')\n    print(f'{Fore.GREEN} Tempo de processamento com {Fore.BLUE} delimitador de espaço {Fore.GREEN}: {format_time(simple_elapsed_time)} {Fore.RESET}')\n    print(\"- - - - - - - - - - -\")\n    \n    # Medindo o desempenho do tokenizador spaCy\n    start_time = time.time()\n    spacy_tokens = spacy_tokenizer(review_text)\n    spacy_elapsed_time = time.time() - start_time\n    \n    print(f'Tokens {Fore.BLUE}spaCy{Fore.RESET}: {spacy_tokens}')\n    print(f'{Fore.GREEN} Tempo de processamento {Fore.BLUE}spaCy{Fore.GREEN}: {format_time(spacy_elapsed_time)} {Fore.RESET}')\n    print(\"- - - - - - - - - - -\")\n    \n    # Medindo o desempenho do tokenizador HuggingFace Transform\n    start_time = time.time()\n    transformers_tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n    hugging_tokens = transformers_tokenizer.tokenize(review_text)\n    hugging_elapsed_time = time.time() - start_time\n\n    print(f'Tokens {Fore.BLUE}HuggingFace{Fore.RESET}: {hugging_tokens}')\n    print(f'{Fore.GREEN} Tempo de processamento {Fore.BLUE}HuggingFace{Fore.GREEN}: {format_time(hugging_elapsed_time)} {Fore.RESET}') \n    \n    print(\"=================================================================\\n\\n\\n\\n\")\n    \nprint(\"\\n************ END ************\")","metadata":{"execution":{"iopub.status.busy":"2023-09-25T23:35:57.864666Z","iopub.execute_input":"2023-09-25T23:35:57.865002Z","iopub.status.idle":"2023-09-25T23:35:59.545320Z","shell.execute_reply.started":"2023-09-25T23:35:57.864979Z","shell.execute_reply":"2023-09-25T23:35:59.543599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. (PP.2.4) Exemplifique o funcionamento de um token de palavras utilizando expressão regular. Explique, com um programa exemplo, como configurar o padrão para obter um comportamento diferente do tokenizador. ","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import regexp_tokenize\n\nfrase = 'Tornar o futuro seguro e Próspero, conectando ciência e Tecnologia!'\n\n# Frase retirando espaços\ntokenizacao1 = regexp_tokenize(frase, r'\\s+', gaps=True)\n\n# Frase selecionando caracter maiúsculo \ntokenizacao2 = regexp_tokenize(frase, r'[A-Z]\\w+')\n\nprint(tokenizacao1)\nprint('---------------------------------------------------------')\nprint(tokenizacao2)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T23:32:33.317762Z","iopub.execute_input":"2023-09-25T23:32:33.318087Z","iopub.status.idle":"2023-09-25T23:32:33.325398Z","shell.execute_reply.started":"2023-09-25T23:32:33.318061Z","shell.execute_reply":"2023-09-25T23:32:33.324102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3. (PP.2.6) Exemplifique o funcionamento de um corretor ortográfico, aplicável à língua portuguesa, que efetue correção de palavras baseado em um corpus de texto considerado como referência e que utilize métricas de distância e estatísticas de ocorrência de palavras no corpus considerado. Alterar o corpus pode afetar o comportamento do corretor? Se sim, dê um exemplo prático utilizando dados diferentes para o corpus.","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-08-29T01:27:23.423042Z","iopub.execute_input":"2023-08-29T01:27:23.423373Z","iopub.status.idle":"2023-08-29T01:27:24.201888Z","shell.execute_reply.started":"2023-08-29T01:27:23.423339Z","shell.execute_reply":"2023-08-29T01:27:24.200782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4. (PP.2.7) Aplique técnicas de tokenização e correção de erros de ortografia a dados de revisão de produtos que tenham sido raspados de uma página de revisão da Internet. Ilustre o comportamento e o desempenho do seu trecho de pipeline de PLN identificando os principais gargalos e sugira uma melhoria possível. Esclareça o porquê da ordem dos elementos em sua pipeline.","metadata":{}},{"cell_type":"code","source":"# Importando bibliotecas\nimport pandas as pd\nimport nltk\nfrom nltk import tokenize    \nfrom nltk.corpus import words\nfrom nltk.metrics.distance import edit_distance\n\n# Definindo frase completa\nfrase = \"Good resolutionn quality hoewever the shape of the packging left somethinggg to be desirred\"\n\n# Tokenizando a frase\ntokens = tokenize.word_tokenize(frase)\nprint(tokens)\nprint('----------------------------------------------------------------')\n\n# Importando palavras corretas\npalavras_corretas = words.words()\nprint(palavras_corretas[:20])\nprint('----------------------------------------------------------------')\n\ndata = []\n\nfor token in tokens:\n    menorDistancia = {\"distancia\": 100, \"palavra\": \"\"}\n    \n    for palavra in palavras_corretas:\n        distancia = edit_distance(token, palavra)\n        if distancia < menorDistancia[\"distancia\"]:\n            menorDistancia[\"distancia\"] = distancia\n            menorDistancia[\"palavra\"] = palavra\n   \n    palavra_corrigida = [menorDistancia[\"palavra\"], menorDistancia[\"distancia\"]]\n    data.append(palavra_corrigida)\n\nprint(data)\nprint('----------------------------------------------------------------')\n\n# for token in tokens:\n#     temp = [(edit_distance(token, palavra), palavra) for palavra in palavras_corretas if palavra[0]==token[0]]\n#     print(sorted(temp, key = lambda val:val[0])[0][1])\n\ndf = pd.DataFrame(data,columns=['Palavra corrigida','Distância'])\ndf.head(50)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T23:47:02.736385Z","iopub.execute_input":"2023-09-25T23:47:02.736767Z","iopub.status.idle":"2023-09-25T23:50:10.580442Z","shell.execute_reply.started":"2023-09-25T23:47:02.736736Z","shell.execute_reply":"2023-09-25T23:50:10.578906Z"},"trusted":true},"execution_count":null,"outputs":[]}]}